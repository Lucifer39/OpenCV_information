{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c975aacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages imported\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "print(\"packages imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cec7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.3.56-cp38-cp38-win_amd64.whl (34.9 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from opencv-python) (1.20.0)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.3.56\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9533801",
   "metadata": {},
   "source": [
    "# Webcam Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdd6bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # 0 for webcam and if you want to capture a local video replace the 0 with the location of the video\n",
    "cap.set(3,640) #height\n",
    "cap.set(4,480) #width\n",
    "cap.set(10,100) #brightness\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"Output\", img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a4387",
   "metadata": {},
   "source": [
    "# Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46da62b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"assets\\car.png\")\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #converting image to greyscale\n",
    "\n",
    "imgBlur = cv2.GaussianBlur(imgGray,(7,7),0) #Image Blur\n",
    "\n",
    "imgCanny = cv2.Canny(img, 150, 200) #Edge Detection\n",
    "\n",
    "imgDilation = cv2.dilate(imgCanny, kernel, iterations=1) #increases the thickness of the edges\n",
    "\n",
    "imgEroded = cv2.erode(imgDilation, kernel, iterations=1) #decrease the thickness of the edges\n",
    "\n",
    "\n",
    "cv2.imshow(\"Output\", imgEroded)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e2123",
   "metadata": {},
   "source": [
    "# Resizing and Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ac47247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"assets\\car.png\")\n",
    "print(img.shape)\n",
    "imgResize = cv2.resize(img, (300,200)) #resizing\n",
    "\n",
    "imgCropped = img[0:200, 200:500] #Cropping a certain part\n",
    "\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow(\"Cropped\", imgCropped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4f1a2",
   "metadata": {},
   "source": [
    "# Shapes and Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18c86526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"assets\\car.png\")\n",
    "imgZero = np.zeros((512,512,3), np.uint8) # black image\n",
    "\n",
    "#print(imgZero.shape)\n",
    "\n",
    "#imgZero[200:300, 100:300]=255,0,0 # coloring the image according to the given range\n",
    "#for coloring the whole image use imgZero[:]\n",
    "\n",
    "#shapes\n",
    "cv2.line(imgZero, (10,10), (400,312), (0,0,255), 2) # draws a line in the image cv2.line(image, starting_point, ending_point, color, thickness)\n",
    "cv2.rectangle(imgZero, (0,0), (200,300), (255,0,0), cv2.FILLED) #draws a rectangle with its diagonal on the starting and end points\n",
    "cv2.circle(imgZero, (450, 50), 30, (0,255,0),5)# draws a circle according to the given centre point and radius\n",
    "\n",
    "#text\n",
    "cv2.putText(imgZero, \"OpenCV\", (212,400),cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0),1)# puts a text on the image according to the given font and scale\n",
    "\n",
    "\n",
    "cv2.imshow(\"Output\", imgZero)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d0e116",
   "metadata": {},
   "source": [
    "# Warped Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d536ff7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv2.imread(\"assets\\cards.png\")\n",
    "img2=cv2.resize(img, (640,480)) #(240,120),(550, 120),(620, 255),(230, 258)\n",
    "#cv2.circle(img2, (230, 258), 10, (0,255,0),2) #used this statement to find the coordinates of the corners\n",
    "\n",
    "width, height = 250,350\n",
    "\n",
    "pts1 = np.float32([[240,120],[550,120],[620,255],[230,258]])# coordinates of the corner points\n",
    "pts2 = np.float32([[width,0],[width,height],[0,height],[0,0]])# coordinates of the corners of the warped image\n",
    "matrix = cv2.getPerspectiveTransform(pts1,pts2) # initaializing a matrix to warp the image\n",
    "\n",
    "imgOutput = cv2.warpPerspective(img2, matrix, (width,height)) # warping the actual image\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\", img2)\n",
    "cv2.imshow(\"After Warped\", imgOutput)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48550939",
   "metadata": {},
   "source": [
    "# Joining Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901bd3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"assets\\car.png\")\n",
    "\n",
    "imghor = np.hstack((img,img)) # stacking two images horizontally\n",
    "imvh = np.vstack((img,img))# stacking two images vertically\n",
    "\n",
    "cv2.imshow(\"Image\", imvh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed5c0d7",
   "metadata": {},
   "source": [
    "# Colour Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7140c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a6141e2ba085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"assets\\cards.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Trackbars\")# creating a new window\n",
    "cv2.resizeWindow(\"Trackbars\", 640,300)# resizing it to our needs\n",
    "cv2.createTrackbar(\"Hue Min\", \"Trackbars\", 0, 179, empty)# (name, window_name, min_value, max_value, function to call at each action on the trackbar)\n",
    "cv2.createTrackbar(\"Hue Max\", \"Trackbars\", 179, 179, empty)\n",
    "cv2.createTrackbar(\"Sat Min\", \"Trackbars\", 0, 255, empty)\n",
    "cv2.createTrackbar(\"Sat Max\", \"Trackbars\", 255, 255, empty)\n",
    "cv2.createTrackbar(\"Val Min\", \"Trackbars\", 0, 255, empty)\n",
    "cv2.createTrackbar(\"Val Max\", \"Trackbars\", 255, 255, empty)\n",
    "\n",
    "while True:\n",
    "    img = cv2.imread(\"assets\\cards.png\")\n",
    "    img2 = cv2.resize(img,(640,480))\n",
    "\n",
    "    imgHSV = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)# converting to HSV scale\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\", \"Trackbars\")# getting the value on the trackbar\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\", \"Trackbars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\", \"Trackbars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\", \"Trackbars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\", \"Trackbars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\", \"Trackbars\")\n",
    "    \n",
    "    lower = np.array([h_min, s_min, v_min])#matrix of the lower threshold values of HSV\n",
    "    upper = np.array([h_max, s_max, v_max])# matrix of upper threshold values of HSV\n",
    "    mask = cv2.inRange(imgHSV, lower, upper)# masking the image in range of HSV values\n",
    "    imgResult = cv2.bitwise_and(img2, img2, mask=mask)\n",
    "    \n",
    "#     cv2.imshow(\"Original\", img2)\n",
    "#     cv2.imshow(\"Image HSV\", imgHSV)\n",
    "#     cv2.imshow(\"Mask\", mask)\n",
    "#     cv2.imshow(\"Result\", imgResult)\n",
    "    imgStack = stackImages(0.6, ([img2,imgHSV], [mask,imgResult]))\n",
    "    cv2.imshow(\"Images\", imgStack)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b32fda",
   "metadata": {},
   "source": [
    "# Contours/Shape Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8020e5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "5193.0\n",
      "Perimeter: 275.2792184352875\n",
      "Approx: 8\n",
      "95.0\n",
      "Perimeter: 751.3523740768433\n",
      "Approx: 13\n",
      "1865.5\n",
      "Perimeter: 186.83556735515594\n",
      "Approx: 4\n",
      "5606.5\n",
      "Perimeter: 364.29141104221344\n",
      "Approx: 3\n",
      "2537.0\n",
      "Perimeter: 201.65685415267944\n",
      "Approx: 4\n",
      "13557.0\n",
      "Perimeter: 501.65685415267944\n",
      "Approx: 4\n",
      "1722.5\n",
      "Perimeter: 158.1248904466629\n",
      "Approx: 8\n",
      "2465.5\n",
      "Perimeter: 188.2670258283615\n",
      "Approx: 8\n",
      "10784.0\n",
      "Perimeter: 416.48528122901917\n",
      "Approx: 4\n",
      "24.5\n",
      "5693.0\n",
      "Perimeter: 286.9360725879669\n",
      "Approx: 8\n",
      "2016.5\n",
      "Perimeter: 224.97770273685455\n",
      "Approx: 4\n",
      "89.0\n",
      "Perimeter: 975.8620405197144\n",
      "Approx: 6\n",
      "5959.0\n",
      "Perimeter: 293.4213538169861\n",
      "Approx: 8\n",
      "1800.5\n",
      "Perimeter: 205.78174459934235\n",
      "Approx: 3\n",
      "1546.5\n",
      "Perimeter: 189.29646337032318\n",
      "Approx: 3\n",
      "2414.0\n",
      "Perimeter: 240.5096664428711\n",
      "Approx: 3\n",
      "2506.5\n",
      "Perimeter: 210.634556889534\n",
      "Approx: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stackImages(scale,imgArray): #this function stacks different image into a single image\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "def getContours(img):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        print(area)\n",
    "        if area>50:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255,0,0), 3) #drawing the contours\n",
    "            perimeter = cv2.arcLength(cnt, True)\n",
    "            print(\"Perimeter:\",perimeter)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02*perimeter, True)# helps in finding the corner coordinates\n",
    "            print(\"Approx:\", len(approx))\n",
    "            objCor = len(approx) #number of corners\n",
    "            x, y, width, height = cv2.boundingRect(approx) \n",
    "            \n",
    "            cv2.rectangle(imgContour, (x,y), (x+width, y+height), (0,255,0), 2)\n",
    "            if objCor==3:\n",
    "                objType=\"Triangle\"\n",
    "            elif objCor == 4:\n",
    "                aspRat=width/float(height)\n",
    "                objType =  \"Square\" if (aspRat>0.95 and aspRat<1.05) else \"Rectangle\"\n",
    "            else:\n",
    "                objType = \"Circle\"\n",
    "            \n",
    "            cv2.putText(imgContour, objType, \n",
    "                        ((x+(width//2)+10), (y+(height//2)-10)), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,0), 2)\n",
    "    \n",
    "\n",
    "img = cv2.imread(\"assets\\shapes.png\")\n",
    "img2 = cv2.resize(img, (640,480))\n",
    "imgContour = img2.copy()\n",
    "\n",
    "imgGray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray, (7,7), 1)\n",
    "imgCanny = cv2.Canny(imgBlur, 50,50)\n",
    "imgBlank = np.zeros_like(img2)\n",
    "getContours(imgCanny)\n",
    "\n",
    "imgStack = stackImages(0.5, ([img2,imgGray],[imgBlur,imgCanny],[imgContour, imgBlank]))\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\", imgStack)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ddc31",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a10d3a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"assets\\DSPicEdit119.JPG\")\n",
    "img2 = cv2.resize(img, (600,540))\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"assets\\haarcascades\\haarcascade_frontalface_default.xml\") #the cascade file helps in detecting faces\n",
    "\n",
    "imgGray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img2, (x,y), ((x+w),(y+h)), (0,255,0), 2)\n",
    "cv2.imshow(\"Image\", img2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e89e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
